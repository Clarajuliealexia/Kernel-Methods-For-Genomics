{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T16:47:51.714676Z",
     "start_time": "2019-02-07T16:47:51.710445Z"
    }
   },
   "source": [
    "# Kernel methods : Data Challenge (TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "import pickle as pkl\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T17:08:51.076236Z",
     "start_time": "2019-02-07T17:08:51.022873Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train(k):\n",
    "    """\n",
    "    Load training data set specified by k\n",
    "    param:\n",
    "        - k: int, which data set to load\n",
    "    return: \n",
    "        - X: pd.DataFrame, features\n",
    "        - y: pd.DataFrame, labels (0/1)\n",
    "    """\n",
    "    X = pd.read_csv('./Data/Xtr'+str(k)+'.csv')\n",
    "    y = pd.read_csv('./Data/Ytr'+str(k)+'.csv').loc[:, \"Bound\"]\n",
    "    return X, y\n",
    "\n",
    "def get_test(k):\n",
    "    """\n",
    "    Load testing data set specified by k\n",
    "    param:\n",
    "        - k: int, which data set to load\n",
    "    return: \n",
    "        - X: pd.DataFrame, features\n",
    "    """\n",
    "    X = pd.read_csv('./Data/Xte'+str(k)+'.csv')\n",
    "    return X\n",
    "    \n",
    "def train_test_split_k(X, y, p):\n",
    "    """\n",
    "    Split training data into training (p%) and testing set (1-p %), with usually p=0.75.\n",
    "    Training and testing data sets are balanced w.r.t to the target y.\n",
    "    param:\n",
    "        - X: pd.DataFrame, features\n",
    "        - y: pd.DataFrame, labels (0/1)\n",
    "    return:\n",
    "        - X_train: pd.DataFrame, training features\n",
    "        - X_test: pd.DataFrame, testing features\n",
    "        - y_train: pd.DataFrame, training labels\n",
    "        - y_test: pd.DataFrame, testing labels\n",
    "    """\n",
    "    n = X.shape[0]\n",
    "    idx_0, idx_1 = np.where(y == 0)[0], np.where(y == 1)[0]\n",
    "    n0, n1 = len(idx_0), len(idx_1)\n",
    "    idx_tr0 = np.random.choice(idx_0, int(p*n0), replace=False)\n",
    "    idx_tr1 = np.random.choice(idx_1, int(p*n1), replace=False)\n",
    "    idx_te0 = list(set(idx_0)-set(idx_tr0))\n",
    "    idx_te1 = list(set(idx_1)-set(idx_tr1))\n",
    "    idx_tr = np.random.permutation(np.concatenate((idx_tr0, idx_tr1)))\n",
    "    idx_te = np.random.permutation(np.concatenate((idx_te0, idx_te1)))\n",
    "    n_tr, n_te = len(idx_tr), len(idx_te)\n",
    "    X_train, y_train = X.iloc[idx_tr, :], y[idx_tr]\n",
    "    X_test, y_test = X.iloc[idx_te, :], y[idx_te]\n",
    "    print('Number of training samples: {} ({:0.2f}%), testing samples: {} ({:0.2f}%)'.\n",
    "          format(n_tr, n_tr/n*100, n_te, n_te/n*100))\n",
    "    print('Count train : 0 ({:0.4f}%), 1 ({:0.4f}%)'.\n",
    "          format(np.count_nonzero(y_train == 0)/n_tr*100,\n",
    "                 np.count_nonzero(y_train == 1)/n_tr*100))\n",
    "    print('Count test : 0 ({:0.4f}%), 1 ({:0.4f}%)\\n'.\n",
    "          format(np.count_nonzero(y_test == 0)/n_te*100,\n",
    "                 np.count_nonzero(y_test == 1)/n_te*100))\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def trainInRepo(file):\n",
    "    """\n",
    "    Check if training data have already been stored in the repo\n",
    "    param:\n",
    "        file: string, file name\n",
    "    return:\n",
    "        Boolean\n",
    "    """\n",
    "    return (file in os.listdir('./Data'))\n",
    "\n",
    "def addColumnK(k, df):\n",
    "    """\n",
    "    Add a column 'k' to flag from which data set the observations come from\n",
    "    param:\n",
    "        - k: int\n",
    "        - df: list of pd.DataFrame(s)\n",
    "    return:\n",
    "        D: list of pd.DataFrame(s) with new colum k\n",
    "    """\n",
    "    D = []\n",
    "    for d in df:\n",
    "        d['k'] = pd.Series([k+1]*d.shape[0], index=d.index)\n",
    "        D.append(d)\n",
    "    return D\n",
    "    \n",
    "def train_test_split():\n",
    "    """\n",
    "    Split training data into training (p%) and testing set (1-p %), with usually p=0.75\n",
    "    for each of the 3 types of TF and concatenate trains and tests.\n",
    "    Training and testing data sets are balanced w.r.t to the target y.\n",
    "    return:\n",
    "        - X_train: pd.DataFrame, training features\n",
    "        - X_test: pd.DataFrame, testing features\n",
    "        - y_train: pd.DataFrame, training labels\n",
    "        - y_test: pd.DataFrame, testing labels\n",
    "    """\n",
    "    for k in range(3):\n",
    "        print('k = '+str(k))\n",
    "        X, y = get_train(k)\n",
    "        if k == 0:\n",
    "            X_train, y_train, X_test, y_test = addColumnK(k, train_test_split_k(X, y, 0.75))\n",
    "        else:\n",
    "            X_tr, y_tr, X_te, y_te = addColumnK(k, train_test_split_k(X, y, 0.75))\n",
    "            X_train = pd.concat((X_train, X_tr), axis=0)\n",
    "            X_test = pd.concat((X_test, X_te), axis=0)\n",
    "            y_train = pd.concat((y_train, y_tr), axis=0)\n",
    "            y_test = pd.concat((y_test, y_te), axis=0)\n",
    "    print('Final shape: train {}, test {}'.format(X_train.shape, X_test.shape))\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def beta(d, k):\n",
    "    """\n",
    "    Compute beta weights for Weighted Degree Kernel\n",
    "    param:\n",
    "        - d: int, maximal degree\n",
    "        - k: int, current degree\n",
    "    return:\n",
    "        - beta: float, weight(k, d)\n",
    "    """\n",
    "    return 2*(d-k+1)/d/(d+1)\n",
    "\n",
    "def get_WD_k(x, y, d, L):\n",
    "    """\n",
    "    Compute, for two sequences x and y, K(x, y)\n",
    "    param:\n",
    "        - x: string, DNA sequence\n",
    "        - y: string, DNA sequence\n",
    "        - d: int, maximal degree\n",
    "        - L: int, length of DNA sequences\n",
    "    return:\n",
    "        - K(x, y): float\n",
    "    """\n",
    "    c_t = 0\n",
    "    for k in range(1, d+1):\n",
    "        beta_k = beta(d, k)\n",
    "        c_st = 0\n",
    "        for l in range(1, L-k+1):\n",
    "            c_st += (x[l:l+k] == y[l:l+k])\n",
    "        c_t += beta_k * c_st\n",
    "    return c_t\n",
    "\n",
    "def get_WD_K(X, d):\n",
    "    """\n",
    "    Compute K(x, y) for each x, y in DNA sequences for Weighted Degree Kernel\n",
    "    param:\n",
    "        - X: pd.DataFrame, features\n",
    "        - d: int, maximal degree\n",
    "    return:\n",
    "        - K: np.array, kernel\n",
    "        - string to describe the method (further used for saving the data)\n",
    "    """\n",
    "    n = X_train.shape[0]\n",
    "    K = np.zeros((n, n))\n",
    "    for i, x in tqdm(enumerate(X.loc[:, 'seq']), total=n, desc='Building kernel'):\n",
    "        L = len(x)\n",
    "        K[i, i] = L - 1 + (1-d)/3\n",
    "        for j, y in enumerate(X.loc[:, 'seq']):\n",
    "            if j > i:\n",
    "                K[i, j] = get_k(x, y, d, L)\n",
    "                K[j, i] = K[i, j]\n",
    "    return K, 'WD'\n",
    "\n",
    "def get_training_datas(d=3, method='WD', replace=False):\n",
    "    """\n",
    "    Construct training and testing data, and kernels. \n",
    "    param:\n",
    "        - d: int, maximal degree\n",
    "        - method: string, method used for computing kernels\n",
    "        - replace: Boolean, whether or not replace the existing files in the repo\n",
    "    return:\n",
    "        - X_train: pd.DataFrame, training features\n",
    "        - X_test: pd.DataFrame, testing features\n",
    "        - y_train: pd.DataFrame, training labels\n",
    "        - y_test: pd.DataFrame, testing labels\n",
    "        - K_train: np.array, training kernel\n",
    "        - K_test: np.array, testing kernel\n",
    "    """\n",
    "    warnings.filterwarnings('ignore')\n",
    "    file = 'training_data_'+str(d)+'_'+method+'.pkl'\n",
    "    if trainInRepo(file) and not replace:\n",
    "        X_train, y_train, X_test, y_test, K_train, K_test = pkl.load(open(os.path.join('./Data', file), 'rb'))\n",
    "    else:\n",
    "        X_train, y_train, X_test, y_test = train_test_split()\n",
    "        K_train, method = get_WD_K(X_train, d)\n",
    "        K_test, _ = get_WD_K(X_test, d)\n",
    "        file = 'training_data_'+str(d)+'_'+method+'.pkl'\n",
    "        pkl.dump([X_train, y_train, X_test, y_test, K_train, K_test], open(os.path.join('./Data', file), 'wb'))\n",
    "    warnings.simplefilter('always')\n",
    "    return X_train, y_train, X_test, y_test, K_train, K_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-07T17:21:15.292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 0\n",
      "Number of training samples: 1499 (74.95%), testing samples: 501 (25.05%)\n",
      "Count train : 0 (51.1674%), 1 (48.8326%)\n",
      "Count test : 0 (51.0978%), 1 (48.9022%)\n",
      "\n",
      "k = 1\n",
      "Number of training samples: 1499 (74.95%), testing samples: 501 (25.05%)\n",
      "Count train : 0 (50.1001%), 1 (49.8999%)\n",
      "Count test : 0 (50.0998%), 1 (49.9002%)\n",
      "\n",
      "k = 2\n",
      "Number of training samples: 1499 (74.95%), testing samples: 501 (25.05%)\n",
      "Count train : 0 (50.0334%), 1 (49.9666%)\n",
      "Count test : 0 (50.0998%), 1 (49.9002%)\n",
      "\n",
      "Final shape: train (4497, 3), test (1503, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a460e7656f5d4b8dab5b1649aaff0264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Building kernel', max=4497, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, K_train, K_test = get_training_datas(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T17:17:36.760163Z",
     "start_time": "2019-02-07T17:17:36.753120Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_k(k, X_train, y_train, X_test, y_test, K_train, K_test):\n",
    "    idx_train = np.where(X_train.loc[:, 'k']==k)[0]\n",
    "    idx_test = np.where(X_test.loc[:, 'k']==k)[0]\n",
    "    X_train_ = X_train.iloc[idx_train]\n",
    "    y_train_ = y_train.iloc[idx_train]\n",
    "    y_test_ = y_test.iloc[idx_test]\n",
    "    X_test_ = X_test.iloc[idx_test]\n",
    "    K_train_ = K_train[idx_train][:, idx_train]\n",
    "    K_test_ = K_test[idx_test][:, idx_test]\n",
    "    return X_train_, y_train_, X_test_, y_test_, K_train_, K_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T17:17:54.067151Z",
     "start_time": "2019-02-07T17:17:53.975257Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_, y_train_, X_test_, y_test_, K_train_, K_test_ = select_k(3, X_train, y_train, X_test, y_test, K_train, K_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
